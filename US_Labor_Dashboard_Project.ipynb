{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# US Labor Dashboard — Project Notebook (Rubric-Aligned)\n", "_Updated 2025-11-15 23:17 UTC_\n", "\n", "This notebook provides a **single, clean, inline-documented** workflow to:\n", "- **Collect** labor statistics from the **BLS Public API** (curated series in four sections).\n", "- **Clean & unify** monthly + quarterly data (Q01..Q04 → Mar/Jun/Sep/Dec).\n", "- **Analyze/visualize** with helper functions (YoY, plots).\n", "- **Export** production files for a **Streamlit dashboard** and a **GitHub Action** that appends new releases monthly.\n", "\n", "**Rubric alignment** (Econ 8320):\n", "- Includes required series (Nonfarm Payrolls, Unemployment Rate) plus other indicators from proposal.\n", "- Data is **not fetched on dashboard load**; a monthly **GitHub Action** updates `data/bls_timeseries.csv`.\n", "- Provides at least a **year+** of history (we fetch **2006–present** by default).\n", "- Streamlit app + automation files are generated in the **Export** section at the end."]}, {"cell_type": "code", "metadata": {}, "source": ["import os, json, requests\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from datetime import datetime\n", "from pathlib import Path\n", "\n", "plt.rcParams['figure.figsize'] = (11, 5)\n", "plt.rcParams['axes.grid'] = True\n", "pd.set_option('display.float_format', lambda x: f\"{x:,.3f}\")\n", "print('Pandas', pd.__version__)"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# =============================\n", "# Configuration with References\n", "# =============================\n", "# Series reflect the proposal categories: Employment, Productivity, Price Index, Compensation.\n", "# CPI is NSA (headline). Productivity series is Q/Q % (PRS85006093). ECI includes both Index (I) and official YoY (A).\n", "START_YEAR = 2006\n", "END_YEAR = datetime.utcnow().year\n", "\n", "SERIES = {\n", "    # Employment (Monthly, SA)\n", "    \"LNS12000000\": {\"section\": \"Employment\", \"name\": \"Civilian Employment (Thousands, SA)\", \"freq\": \"M\"},\n", "    \"CES0000000001\": {\"section\": \"Employment\", \"name\": \"Total Nonfarm Employment (Thousands, SA)\", \"freq\": \"M\"},\n", "    \"LNS14000000\": {\"section\": \"Employment\", \"name\": \"Unemployment Rate (% SA)\", \"freq\": \"M\"},\n", "    \"CES0500000002\": {\"section\": \"Employment\", \"name\": \"Avg Weekly Hours, Total Private (SA)\", \"freq\": \"M\"},\n", "    \"CES0500000003\": {\"section\": \"Employment\", \"name\": \"Avg Hourly Earnings, Total Private ($, SA)\", \"freq\": \"M\"},\n", "    # Productivity (Quarterly, SA) — Q/Q %\n", "    \"PRS85006093\": {\"section\": \"Productivity\", \"name\": \"Output per Hour — Nonfarm Business (Q/Q %)\", \"freq\": \"Q\"},\n", "    # Price Index (Monthly, NSA)\n", "    \"CUUR0000SA0\": {\"section\": \"Price Index\", \"name\": \"CPI-U All Items (NSA, 1982–84=100)\", \"freq\": \"M\"},\n", "    # Compensation (Quarterly, NSA)\n", "    \"CIU1010000000000I\": {\"section\": \"Compensation\", \"name\": \"ECI — Total Compensation, Private (Index, NSA)\", \"freq\": \"Q\"},\n", "    \"CIU1010000000000A\": {\"section\": \"Compensation\", \"name\": \"ECI — Total Compensation, Private (12m % change, NSA)\", \"freq\": \"Q\"},\n", "}\n", "\n", "BLS_URL = \"https://api.bls.gov/publicAPI/v2/timeseries/data/\""], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# ============================\n", "# Fetch & Parse (with docstrings)\n", "# ============================\n", "class BLSError(Exception):\n", "    \"\"\"BLS API error (HTTP or logical).\"\"\"\n", "    pass\n", "\n", "def fetch_bls_timeseries(series_ids, start_year, end_year):\n", "    \"\"\"\n", "    Fetch multiple BLS series using v2 API in a single POST.\n", "    Honors BLS_API_KEY if present for higher limits.\n", "    \"\"\"\n", "    payload = {\"seriesid\": series_ids, \"startyear\": str(start_year), \"endyear\": str(end_year)}\n", "    key = os.getenv(\"BLS_API_KEY\")\n", "    if key:\n", "        payload[\"registrationkey\"] = key\n", "    r = requests.post(BLS_URL, json=payload, timeout=60)\n", "    if r.status_code != 200:\n", "        raise BLSError(f\"HTTP {r.status_code}: {r.text[:200]}\")\n", "    data = r.json()\n", "    if data.get(\"status\") != \"REQUEST_SUCCEEDED\":\n", "        raise BLSError(f\"BLS error: {json.dumps(data)[:300]}\")\n", "    return data\n", "\n", "def _q_to_month(q: int) -> int:\n", "    \"\"\"Quarter → quarter-ending month mapping: Q1→3, Q2→6, Q3→9, Q4→12.\"\"\"\n", "    return {1: 3, 2: 6, 3: 9, 4: 12}[q]\n", "\n", "def series_payload_to_rows(series_json):\n", "    \"\"\"\n", "    Convert a single BLS 'series' JSON block to tidy rows.\n", "    Accepts monthly (M01..M12) and quarterly (Q01..Q04). Skips M13 (annual avg).\n", "    \"\"\"\n", "    sid = series_json[\"seriesID\"]\n", "    rows = []\n", "    for item in series_json[\"data\"]:\n", "        p = item.get(\"period\")\n", "        if not p or p == \"M13\":\n", "            continue\n", "        year = int(item[\"year\"])\n", "        if p.startswith(\"M\"):\n", "            month = int(p[1:])\n", "        elif p.startswith(\"Q\"):\n", "            month = _q_to_month(int(p[1:]))\n", "        else:\n", "            continue\n", "        dt = pd.Timestamp(year=year, month=month, day=1)\n", "        val = float(item[\"value\"])\n", "        rows.append({\"series_id\": sid, \"date\": dt, \"value\": val})\n", "    return rows"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# =============================\n", "# Build the long-form DataFrame\n", "# =============================\n", "api = fetch_bls_timeseries(list(SERIES.keys()), START_YEAR, END_YEAR)\n", "rows = [r for s in api[\"Results\"][\"series\"] for r in series_payload_to_rows(s)]\n", "df = pd.DataFrame(rows).sort_values([\"series_id\", \"date\"]).reset_index(drop=True)\n", "print(\"Rows:\", len(df), \"Series:\", df[\"series_id\"].nunique())\n", "df.head()"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# ======================\n", "# Transform & Plot Utils\n", "# ======================\n", "def _lag_for_yoy(sid: str) -> int:\n", "    freq = SERIES.get(sid, {}).get(\"freq\", \"M\").upper()\n", "    return 4 if freq.startswith(\"Q\") else 12\n", "\n", "def yoy_from_level(df_long: pd.DataFrame, sid: str) -> pd.DataFrame:\n", "    d = (df_long[df_long.series_id == sid]\n", "         .set_index(\"date\")\n", "         .sort_index()[[\"value\"]]\n", "         .copy())\n", "    lag = _lag_for_yoy(sid)\n", "    d[\"yoy_pct\"] = d[\"value\"].pct_change(lag) * 100.0\n", "    return d\n", "\n", "def plot_series(df_long: pd.DataFrame, series_ids, title=None, ylabel=None, since=None):\n", "    sub = df_long[df_long.series_id.isin(series_ids)].copy()\n", "    if since is not None:\n", "        sub = sub[sub.date >= pd.to_datetime(since)]\n", "    name_map = {sid: SERIES.get(sid, {}).get(\"name\", sid) for sid in series_ids}\n", "    for sid in series_ids:\n", "        d = sub[sub.series_id == sid].copy()\n", "        plt.figure()\n", "        plt.plot(d[\"date\"], d[\"value\"])\n", "        ttl = title if (title and len(series_ids) == 1) else name_map.get(sid, sid)\n", "        plt.title(ttl)\n", "        plt.xlabel(\"Date\")\n", "        plt.ylabel(ylabel or \"Value\")\n", "        plt.show()\n", "\n", "def plot_yoy_from_level(df_long: pd.DataFrame, sid: str, title_suffix=\" (YoY %)\"):\n", "    d = yoy_from_level(df_long, sid)\n", "    plt.figure()\n", "    plt.plot(d.index, d[\"yoy_pct\"])\n", "    plt.title(SERIES.get(sid, {}).get(\"name\", sid) + title_suffix)\n", "    plt.xlabel(\"Date\")\n", "    plt.ylabel(\"YoY %\")\n", "    plt.show()"], "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["# ======================\n", "# Example Charts (run)\n", "# ======================\n", "# Employment\n", "plot_series(df, [\"LNS12000000\", \"CES0000000001\", \"LNS14000000\", \"CES0500000002\", \"CES0500000003\"], since=f\"{START_YEAR}-01-01\")\n", "\n", "# Wages YoY\n", "plot_yoy_from_level(df, \"CES0500000003\")\n", "\n", "# Productivity (Q/Q %)\n", "plot_series(df, [\"PRS85006093\"], ylabel=\"Q/Q %\", title=\"Output per Hour — Nonfarm Business (Q/Q %)\", since=f\"{START_YEAR}-01-01\")\n", "\n", "# CPI level & YoY\n", "plot_series(df, [\"CUUR0000SA0\"], ylabel=\"Index\", title=\"CPI-U All Items (NSA, 1982–84=100)\", since=f\"{START_YEAR}-01-01\")\n", "plot_yoy_from_level(df, \"CUUR0000SA0\")\n", "\n", "# ECI: official YoY & YoY-from-index\n", "plot_series(df, [\"CIU1010000000000A\"], ylabel=\"%\", title=\"ECI — Total Compensation, Private (12m % change, NSA)\", since=f\"{START_YEAR}-01-01\")\n", "plot_yoy_from_level(df, \"CIU1010000000000I\", title_suffix=\" (YoY from Index)\")"], "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## Export: generate Streamlit app, updater script, GitHub Action, requirements\n", "Run the next cell once to write production files into the working directory.\n", "- `bls_update.py` (API → CSV, incremental appender)\n", "- `streamlit_app.py` (interactive dashboard with filters & recession shading)\n", "- `.github/workflows/update.yml` (twice-monthly schedule)\n", "- `requirements.txt`"]}, {"cell_type": "code", "metadata": {}, "source": ["from pathlib import Path\n", "\n", "DATA_DIR = Path(\"data\"); DATA_DIR.mkdir(exist_ok=True, parents=True)\n", "\n", "bls_update_py = r\"\"\"#!/usr/bin/env python3\n", "import os, json, requests\n", "from datetime import datetime\n", "from pathlib import Path\n", "import pandas as pd\n", "\n", "START_YEAR = 2006\n", "END_YEAR = datetime.utcnow().year\n", "\n", "SERIES = {\n", "    \"LNS12000000\": {\"section\": \"Employment\", \"name\": \"Civilian Employment (Thousands, SA)\", \"freq\": \"M\"},\n", "    \"CES0000000001\": {\"section\": \"Employment\", \"name\": \"Total Nonfarm Employment (Thousands, SA)\", \"freq\": \"M\"},\n", "    \"LNS14000000\": {\"section\": \"Employment\", \"name\": \"Unemployment Rate (% SA)\", \"freq\": \"M\"},\n", "    \"CES0500000002\": {\"section\": \"Employment\", \"name\": \"Avg Weekly Hours, Total Private (SA)\", \"freq\": \"M\"},\n", "    \"CES0500000003\": {\"section\": \"Employment\", \"name\": \"Avg Hourly Earnings, Total Private ($, SA)\", \"freq\": \"M\"},\n", "    \"PRS85006093\": {\"section\": \"Productivity\", \"name\": \"Output per Hour — Nonfarm Business (Q/Q %)\", \"freq\": \"Q\"},\n", "    \"CUUR0000SA0\": {\"section\": \"Price Index\", \"name\": \"CPI-U All Items (NSA, 1982–84=100)\", \"freq\": \"M\"},\n", "    \"CIU1010000000000I\": {\"section\": \"Compensation\", \"name\": \"ECI — Total Compensation, Private (Index, NSA)\", \"freq\": \"Q\"},\n", "    \"CIU1010000000000A\": {\"section\": \"Compensation\", \"name\": \"ECI — Total Compensation, Private (12m % change, NSA)\", \"freq\": \"Q\"},\n", "}\n", "\n", "BLS_URL = \"https://api.bls.gov/publicAPI/v2/timeseries/data/\"\n", "DATA_DIR = Path(\"data\")\n", "CSV_PATH = DATA_DIR / \"bls_timeseries.csv\"\n", "META_PATH = DATA_DIR / \"meta.json\"\n", "DATA_DIR.mkdir(parents=True, exist_ok=True)\n", "\n", "class BLSError(Exception): pass\n", "\n", "def fetch_bls_timeseries(series_ids, start_year, end_year):\n", "    payload = {\"seriesid\": series_ids, \"startyear\": str(start_year), \"endyear\": str(end_year)}\n", "    key = os.getenv(\"BLS_API_KEY\")\n", "    if key:\n", "        payload[\"registrationkey\"] = key\n", "    r = requests.post(BLS_URL, json=payload, timeout=60)\n", "    if r.status_code != 200:\n", "        raise BLSError(f\"HTTP {r.status_code}: {r.text[:200]}\")\n", "    data = r.json()\n", "    if data.get(\"status\") != \"REQUEST_SUCCEEDED\":\n", "        raise BLSError(f\"BLS error: {json.dumps(data)[:300]}\")\n", "    return data\n", "\n", "def _q_to_month(q: int) -> int:\n", "    return {1: 3, 2: 6, 3: 9, 4: 12}[q]\n", "\n", "def series_payload_to_rows(series_json):\n", "    sid = series_json[\"seriesID\"]\n", "    rows = []\n", "    for item in series_json[\"data\"]:\n", "        p = item.get(\"period\")\n", "        if not p or p == \"M13\":\n", "            continue\n", "        year = int(item[\"year\"])\n", "        if p.startswith(\"M\"):\n", "            month = int(p[1:])\n", "        elif p.startswith(\"Q\"):\n", "            month = _q_to_month(int(p[1:]))\n", "        else:\n", "            continue\n", "        dt = pd.Timestamp(year=year, month=month, day=1)\n", "        val = float(item[\"value\"])\n", "        rows.append({\"series_id\": sid, \"date\": dt, \"value\": val})\n", "    return rows\n", "\n", "def load_existing():\n", "    if CSV_PATH.exists():\n", "        return pd.read_csv(CSV_PATH, parse_dates=[\"date\"])\n", "    return pd.DataFrame(columns=[\"series_id\", \"date\", \"value\"])\n", "\n", "def union_and_dedupe(df_old, df_new):\n", "    df = pd.concat([df_old, df_new], ignore_index=True)\n", "    df = df.drop_duplicates(subset=[\"series_id\", \"date\"], keep=\"last\")\n", "    return df.sort_values([\"series_id\", \"date\"]).reset_index(drop=True)\n", "\n", "def run_full_or_incremental():\n", "    df_old = load_existing()\n", "    start = START_YEAR if df_old.empty else max(START_YEAR, (df_old['date'].max() - pd.DateOffset(months=24)).year)\n", "    api = fetch_bls_timeseries(list(SERIES.keys()), start, END_YEAR)\n", "    rows = [r for s in api[\"Results\"][\"series\"] for r in series_payload_to_rows(s)]\n", "    df_new = pd.DataFrame(rows)\n", "    df_out = union_and_dedupe(df_old, df_new)\n", "    df_out.to_csv(CSV_PATH, index=False)\n", "    META_PATH.write_text(json.dumps({\"last_updated_utc\": datetime.utcnow().isoformat()}, indent=2))\n", "    print(f\"Updated {len(df_out)} rows → {CSV_PATH}\")\n", "    return df_out\n", "\n", "if __name__ == \"__main__\":\n", "    run_full_or_incremental()\n", "\"\"\"\n", "\n", "streamlit_app_py = r\"\"\"import json\n", "from pathlib import Path\n", "import pandas as pd\n", "import streamlit as st\n", "import plotly.express as px\n", "from datetime import datetime\n", "\n", "DATA_DIR = Path(\"data\")\n", "CSV_PATH = DATA_DIR / \"bls_timeseries.csv\"\n", "META_PATH = DATA_DIR / \"meta.json\"\n", "\n", "SERIES = {\n", "    \"LNS12000000\": {\"section\": \"Employment\", \"name\": \"Civilian Employment (Thousands, SA)\", \"freq\": \"M\"},\n", "    \"CES0000000001\": {\"section\": \"Employment\", \"name\": \"Total Nonfarm Employment (Thousands, SA)\", \"freq\": \"M\"},\n", "    \"LNS14000000\": {\"section\": \"Employment\", \"name\": \"Unemployment Rate (% SA)\", \"freq\": \"M\"},\n", "    \"CES0500000002\": {\"section\": \"Employment\", \"name\": \"Avg Weekly Hours, Total Private (SA)\", \"freq\": \"M\"},\n", "    \"CES0500000003\": {\"section\": \"Employment\", \"name\": \"Avg Hourly Earnings, Total Private ($, SA)\", \"freq\": \"M\"},\n", "    \"PRS85006093\": {\"section\": \"Productivity\", \"name\": \"Output per Hour — Nonfarm Business (Q/Q %)\", \"freq\": \"Q\"},\n", "    \"CUUR0000SA0\": {\"section\": \"Price Index\", \"name\": \"CPI-U All Items (NSA, 1982–84=100)\", \"freq\": \"M\"},\n", "    \"CIU1010000000000I\": {\"section\": \"Compensation\", \"name\": \"ECI — Total Compensation, Private (Index, NSA)\", \"freq\": \"Q\"},\n", "    \"CIU1010000000000A\": {\"section\": \"Compensation\", \"name\": \"ECI — Total Compensation, Private (12m % change, NSA)\", \"freq\": \"Q\"},\n", "}\n", "\n", "SECTIONS = [\"Employment\", \"Productivity\", \"Price Index\", \"Compensation\"]\n", "RECESSIONS = [\n", "    (pd.Timestamp(2007, 12, 1), pd.Timestamp(2009, 6, 1)),\n", "    (pd.Timestamp(2020, 2, 1), pd.Timestamp(2020, 4, 1)),\n", "]\n", "\n", "@st.cache_data\n", "def load_data():\n", "    df = pd.read_csv(CSV_PATH, parse_dates=[\"date\"])\n", "    df[\"series_id\"] = df[\"series_id\"].astype(\"string\")\n", "    return df\n", "\n", "def yoy_from_level(df, sid):\n", "    freq = SERIES.get(sid, {}).get(\"freq\", \"M\").upper()\n", "    lag = 4 if freq.startswith(\"Q\") else 12\n", "    d = df[df.series_id == sid][[\"date\", \"value\"]].sort_values(\"date\").set_index(\"date\").copy()\n", "    d[\"YoY %\"] = d[\"value\"].pct_change(lag) * 100.0\n", "    d = d.reset_index()\n", "    d[\"series_id\"] = sid\n", "    return d\n", "\n", "def add_recession_shading(fig):\n", "    for (start, end) in RECESSIONS:\n", "        fig.add_vrect(x0=start, x1=end, fillcolor=\"gray\", opacity=0.15, line_width=0)\n", "    return fig\n", "\n", "def main():\n", "    st.set_page_config(page_title=\"US Labor Dashboard\", layout=\"wide\")\n", "    st.title(\"US Labor Dashboard\")\n", "    st.caption(\"Auto-updating BLS dashboard (Econ 8320 project)\")\n", "\n", "    with st.expander(\"About & rubric alignment\", expanded=False):\n", "        st.markdown(\n", "            \"- Uses BLS Public API via monthly/quarterly fetcher (stored to CSV; no live fetch on every app load).\\n\"\n", "            \"- Includes required series: Nonfarm Employment & Unemployment Rate; plus additional sections from proposal.\\n\"\n", "            \"- Updates via GitHub Actions twice monthly to catch major releases.\\n\"\n", "            \"- Filter by section/series and date range; optional YoY visuals for CPI, Wages, ECI index.\"\n", "        )\n", "\n", "    if META_PATH.exists():\n", "        meta = json.loads(META_PATH.read_text())\n", "        st.caption(f\"Last updated (UTC): {meta.get('last_updated_utc', 'unknown')}\")\n", "\n", "    section = st.sidebar.multiselect(\"Sections\", SECTIONS, default=SECTIONS)\n", "    eligible = [sid for sid, m in SERIES.items() if m[\"section\"] in section]\n", "    pick = st.sidebar.multiselect(\n", "        \"Series\",\n", "        eligible,\n", "        format_func=lambda x: f\"{SERIES[x]['section']} — {SERIES[x]['name']}\",\n", "        default=eligible,\n", "    )\n", "    year_min, year_max = st.sidebar.slider(\"Year range\", 2006, datetime.utcnow().year, (2006, datetime.utcnow().year))\n", "\n", "    if not CSV_PATH.exists():\n", "        st.error(\"Data file not found. Run bls_update.py first.\")\n", "        return\n", "    df = load_data()\n", "    df = df[df[\"series_id\"].isin(pick)]\n", "    df = df[(df[\"date\"].dt.year >= year_min) & (df[\"date\"].dt.year <= year_max)]\n", "\n", "    st.download_button(\"Download full CSV\", CSV_PATH.read_bytes(), file_name=\"bls_timeseries.csv\")\n", "    st.download_button(\"Download filtered CSV\", df.to_csv(index=False).encode(\"utf-8\"), file_name=\"bls_timeseries_filtered.csv\")\n", "\n", "    for sec in SECTIONS:\n", "        sub_ids = [sid for sid in pick if SERIES[sid][\"section\"] == sec]\n", "        if not sub_ids:\n", "            continue\n", "        st.subheader(sec)\n", "        for sid in sub_ids:\n", "            name = SERIES[sid][\"name\"]\n", "            d = df[df.series_id == sid].sort_values(\"date\")\n", "            if d.empty: continue\n", "            fig = px.line(d, x=\"date\", y=\"value\", title=name, labels={\"value\": \"Value\", \"date\": \"Date\"})\n", "            fig = add_recession_shading(fig)\n", "            st.plotly_chart(fig, use_container_width=True)\n", "\n", "            if sid in [\"CUUR0000SA0\", \"CES0500000003\", \"CIU1010000000000I\"]:\n", "                yoy = yoy_from_level(df, sid).dropna()\n", "                if not yoy.empty:\n", "                    fig2 = px.line(yoy, x=\"date\", y=\"YoY %\", title=f\"{name} — YoY %\")\n", "                    fig2 = add_recession_shading(fig2)\n", "                    st.plotly_chart(fig2, use_container_width=True)\n", "\n", "    st.write(\"---\")\n", "    st.caption(\"Notes: CPI is NSA; productivity series is Q/Q %; ECI shown as official YoY and YoY computed from the index.\")\n", "\n", "if __name__ == \"__main__\":\n", "    main()\n", "\"\"\"\n", "\n", "workflow_yml = r\"\"\"name: Update BLS data monthly\n", "on:\n", "  workflow_dispatch: {}\n", "  schedule:\n", "    - cron: \"0 10 5 * *\"\n", "    - cron: \"0 10 15 * *\"\n", "jobs:\n", "  update:\n", "    runs-on: ubuntu-latest\n", "    permissions:\n", "      contents: write\n", "    steps:\n", "      - name: Checkout\n", "        uses: actions/checkout@v4\n", "      - name: Set up Python\n", "        uses: actions/setup-python@v5\n", "        with:\n", "          python-version: \"3.11\"\n", "      - name: Install deps\n", "        run: |\n", "          python -m pip install --upgrade pip\n", "          pip install -r requirements.txt\n", "      - name: Update BLS data\n", "        env:\n", "          BLS_API_KEY: ${{ secrets.BLS_API_KEY }}\n", "        run: python bls_update.py\n", "      - name: Commit & push\n", "        run: |\n", "          git config user.name \"github-actions[bot]\"\n", "          git config user.email \"github-actions[bot]@users.noreply.github.com\"\n", "          git add data/bls_timeseries.csv data/meta.json\n", "          git commit -m \"ci: monthly BLS data update [skip ci]\" || echo \"No changes\"\n", "          git push\n", "\"\"\"\n", "\n", "requirements_txt = \"pandas>=2.1\n", "requests>=2.31\n", "streamlit>=1.36\n", "plotly>=5.20\n", "\"\n", "\n", "# Write files\n", "Path(\"bls_update.py\").write_text(bls_update_py)\n", "Path(\"streamlit_app.py\").write_text(streamlit_app_py)\n", "Path(\".github/workflows\").mkdir(parents=True, exist_ok=True)\n", "Path(\".github/workflows/update.yml\").write_text(workflow_yml)\n", "Path(\"requirements.txt\").write_text(requirements_txt)\n", "\n", "print(\"Exported: bls_update.py, streamlit_app.py, .github/workflows/update.yml, requirements.txt\")"], "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}